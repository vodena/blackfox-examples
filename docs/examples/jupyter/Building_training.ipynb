{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Building\n  \n### Problem explanation:\n\nPrediction of energy consumption in a building. Try to predict the hourly consumption of electrical energy, hot water, and cold water, based on the date, time of day, outside temperature, outside air humidity, solar radiation, and wind speed.\nThe data set was created based on problem A of “The Great Energy Predictor Shootout - the first building data analysis and prediction problem” contest, organized in 1993 for the ASHRAE мeeting in Denver, Colorado. The data set itself is located here, in the field building.\n\nThis is regression problem and the results  are three outputs, hourly consumption of electrical energy, hot water, and cold water. Model inputs are:\n \n* Day,\n* Hour,\n* Temperature,\n* Humidity,\n* Solar radiation,\n* Wind speed.\n\n### Problem solution:\nData set contains 4208 observations,we have divided the data set in two sets, training set, which contains 3366 observations and test set, which contains 842 observations. We solved problem in two ways, with Python and Black Fox. We measured the model performance with K-cross validation (K=5) and for feature scaling we used min-max scaler. Input day is categorical data, so it was encoded with one hot encoder (to avoid dummy variable trap we ignored, for example monday) and the hour, as cyclic data was encoded with distance of noon. To stop training at the right time we used Early Stopping.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Update Keras to latest version:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install keras==2.2.4",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Data preprocessing\n#### Importing dataset:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\ndataframe = pd.read_csv('BuildingData.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Dataset info:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dataframe.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Dataset description:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dataframe.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Dataset histogram:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dataframe.hist(figsize=(14,14));",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Corelation heatmap:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.heatmap(dataframe.corr(), vmin=0, vmax=1);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### We will separate data frame into matrix X of features and dependent variable which is matrix y."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X = dataframe.iloc[:, 0:14].values\ny = dataframe.iloc[:, 14:17].values\n\n# To avoid dummy variable trap we remove column.\nX = X[:, 1:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Now we are able to split the dataset into the training set and test set."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### We need to apply feature scaling because we don't wanna have one independent variable dominating another one."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Min Max Scaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX_train_minMaxScaled = scaler.fit_transform(X_train)\nX_test_minMaxScaled = scaler.transform(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Option 1 - manually finding best ANN:\n#### After many times of guessing the parameters for model this are the best one that we have found (you dont see our such enormous effort and huge time to find this parameters)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Importing the keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import Callback, TensorBoard, ModelCheckpoint\nfrom keras.callbacks import EarlyStopping\n\nimport time\nstart1 = time.time()\n\nclassifier = Sequential()\nclassifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = 13))\nclassifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'sigmoid'))\nclassifier.add(Dense(units = 3, kernel_initializer = 'uniform', activation = 'sigmoid'))\nes = EarlyStopping(monitor = 'val_loss',\n                   mode = 'auto',\n                   #min_delta = 0,\n                   patience = 200,\n                   verbose = 1,\n                   #baseline=0.4,\n                   restore_best_weights = True\n                  )\nclassifier.compile(optimizer = 'nadam', loss = 'mean_absolute_error', metrics = ['accuracy'])\nclassifier.fit(x = X_train_minMaxScaled, y = y_train, validation_split = 0.3, batch_size = 32, epochs = 3000, callbacks = [es], verbose=1)\n\nend1 = time.time()\n\ntime1 = int(end1-start1)\nminutes1, seconds1= divmod(time1, 60)\nhours1, minutes1= divmod(minutes1, 60)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "cell_type": "markdown",
      "source": "#### We just trained our artificial neural network on the training set and now it's time to make the prediction on the test set."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_pred_trained = classifier.predict(X_test_minMaxScaled)\nprint(\"Predicted values are:\\n\\n\", y_pred_trained[:10,:])\n\nt1=y_pred_trained - y_test\nt2=np.square(t1)\n\nt21=t2[:,0:1]\nt22=t2[:,1:2]\nt23=t2[:,2:3]\n\nt31=t21.sum()\nt32=t22.sum()\nt33=t23.sum()\n\nt41=t31/y_test.shape[0]\nt42=t32/y_test.shape[0]\nt43=t33/y_test.shape[0]\n\nRmse1_trained = np.sqrt(t41)\nRmse2_trained = np.sqrt(t42)\nRmse3_trained = np.sqrt(t43)\n\nt_max1 = np.max(y_test[:,0:1])\nt_min1 = np.min(y_test[:,0:1])\nt_max2 = np.max(y_test[:,1:2])\nt_min2 = np.min(y_test[:,1:2])\nt_max3 = np.max(y_test[:,2:3])\nt_min3 = np.min(y_test[:,2:3])\n\nPrmse1_trained = 100 * (Rmse1_trained / (t_max1 - t_min1))\nPrmse2_trained = 100 * (Rmse2_trained / (t_max2 - t_min2))\nPrmse3_trained = 100 * (Rmse3_trained / (t_max3 - t_min3))\n\nprint(\"\\nTime to manually train one network is \", time1,\"seconds(\",hours1,\"hours,\",minutes1,\"minutes and \",seconds1,\"seconds ).\")\nprint(\"\\nRmse(WBE) = \",Rmse1_trained)\nprint(\"Rmse(WBCW) = \",Rmse2_trained)\nprint(\"Rmse(WBHW) = \",Rmse3_trained)\nprint(\"\\nPrmse(WBE) = \",Prmse1_trained)\nprint(\"Prmse(WBCW) = \",Prmse2_trained)\nprint(\"Prmse(WBHW) = \",Prmse3_trained)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Option 2 - Parameter tuning\n#### We have two type of parameters,  the parameters that are leaned from the model during the training and these are the weights, and we have some other parameters that stay fixed, and this parameters are called the hyperparameters. So for example this hyperparameters are the number of epoch, the bach size, the optimizer or the number of neurons in the layers. When we trained our ANN, we trained it with some fixed values of this hyperparameters, but meybe that by taking some other values we would get to better accuracy over all with K cross validation, and so that's what parameter tuning is all about, it consists of finding the best values of this hyperparameters and we are gonna do this with the technique called grid search that will test several combinations of this values and it will return the best choise that leads to the best accuracy with K cross validation."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nimport time\nstart2 = time.time()\n\ndef build_classifier(optimizer):\n   classifier = Sequential()\n   classifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = 13))\n   classifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'sigmoid'))\n   classifier.add(Dense(units = 3, kernel_initializer = 'uniform', activation = 'sigmoid'))\n   classifier.compile(optimizer = optimizer, loss = 'mean_absolute_error', metrics = ['accuracy'])\n   return classifier\n\nTuning_classifier = KerasClassifier(build_fn = build_classifier)\nparameters = {'batch_size': [10, 25, 32],\n              'epochs': [100, 500, 3000],\n              'optimizer': ['adam', 'rmsprop']\n             }\n\ngrid_search = GridSearchCV(estimator = Tuning_classifier,\n                           param_grid = parameters,\n                           #scoring = 'accuracy',\n                           cv = 10,\n                          )\n\ngrid_search = grid_search.fit(X_train_minMaxScaled, y_train)\n\nbest_parameters = grid_search.best_params_\nbest_accuracy = grid_search.best_score_\n\nprint(\"Best parameters are :\\n\", best_parameters)\nprint(\"\\nBest accuracy is :\\n\", best_accuracy)\n\n\nend2 = time.time()\n\ntime2 = int(end2-start2)\nminutes2, seconds2= divmod(time2, 60)\nhours2, minutes2= divmod(minutes2, 60)\n\nprint(\"\\nTime training one network is \", time2,\"seconds(\",hours2,\"hours,\",minutes2,\"minutes and \",seconds2,\"seconds).\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### We got our artificial neural network which is in model named \"grid_search\". Now it's time to make the prediction on the test set."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_pred_tuning = grid_search.predict_proba(X_test_minMaxScaled)\n#print(\"Predicted values are:\\n\\n\", y_pred_tuning[:10,:])\n\nt1=y_pred_tuning - y_test\nt2=np.square(t1)\n\nt21=t2[:,0:1]\nt22=t2[:,1:2]\nt23=t2[:,2:3]\n\nt31=t21.sum()\nt32=t22.sum()\nt33=t23.sum()\n\nt41=t31/y_test.shape[0]\nt42=t32/y_test.shape[0]\nt43=t33/y_test.shape[0]\n\nRmse1_tuning = np.sqrt(t41)\nRmse2_tuning = np.sqrt(t42)\nRmse3_tuning = np.sqrt(t43)\n\nt_max1 = np.max(y_test[:,0:1]\nt_min1 = np.min(y_test[:,0:1]\nt_max2 = np.max(y_test[:,1:2]\nt_min2 = np.min(y_test[:,1:2]\nt_max3 = np.max(y_test[:,2:3]\nt_min3 = np.min(y_test[:,2:3]\n\nPrmse1_tuning = 100 * (Rmse1_tuning / (t_max1 - t_min1))\nPrmse2_tuning = 100 * (Rmse2_tuning / (t_max2 - t_min2))\nPrmse3_tuning = 100 * (Rmse3_tuning / (t_max3 - t_min3))\n\nprint(\"\\nTime needed for tuning is \", time2,\"seconds(\",hours2,\"hours,\",minutes2,\"minutes and \",seconds2,\"seconds).\")\nprint(\"\\nRmse(WBE) = \",Rmse1_tuning)\nprint(\"Rmse(WBCW) = \",Rmse2_tuning)\nprint(\"Rmse(WBHW) = \",Rmse3_tuning)\nprint(\"\\nPrmse(WBE) = \",Prmse1_tuning)\nprint(\"Prmse(WBCW) = \",Prmse2_tuning)\nprint(\"Prmse(WBHW) = \",Prmse3_tuning)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Option 3 - Black fox service finding best ANN:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "#### Install Black fox service:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install blackfox-1.0.0.0.tar.gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "#### Let's run Black Fox service to find best ANN:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Importing the BF service libraries\nfrom blackfox import BlackFox\nfrom blackfox import KerasOptimizationConfig\nfrom blackfox import OptimizationEngineConfig\n\nblackfox_url = 'http://147.91.204.14:32701'\nbf = BlackFox(blackfox_url)\n\nec = OptimizationEngineConfig(proc_timeout_miliseconds=2000000, population_size=50, max_num_of_generations=10)\nc = KerasOptimizationConfig(engine_config=ec, max_epoch = 3000, validation_split=0.3)\n\nimport time\nstart3 = time.time()\n\n# Use CTRL + C to stop optimization\n(ann_io, ann_info, ann_metadata) = bf.optimize_keras_sync(\n    input_set = X_train,\n    output_set = y_train,\n    config = c,\n    integrate_scaler=False,\n    network_path='OptimizedANNBuilding_final.h5'\n)\n\nend3 = time.time()\ntime3 = int(end3-start3)\n\nprint('\\nann info:')\nprint(ann_info)\n\nprint('\\nann metadata:')\nprint(ann_metadata)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Data that we transfer to Black Fox service are not scaled, the service will scale the date by its own and when he finish his job he won't change the data, but service ofers us command to scale our data for prediction as he did and we will ofcourse use that."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Get metadata\nmeta = bf.get_metadata('OptimizedANNBuilding_final.h5')\nscaler_config = meta['scaler_config']\n\n# Scale\nx_scaler_config = scaler_config['input']\nfrom sklearn.preprocessing import MinMaxScaler \nmin_max_x = MinMaxScaler(feature_range=x_scaler_config['feature_range'])\nmin_max_x.fit(x_scaler_config['fit'])\n\nX_test_minMaxScaled_withBF = min_max_x.transform(X_test)\n#print(X_test_minMaxScaled_withBF[:10,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Prediction:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Importing ANN model\nfrom keras.models import load_model\nmodel = load_model('OptimizedANNBuilding_final.h5')\n\n#Prediction\ny_pred_BF=model.predict(X_test_minMaxScaled_withBF)\n#print(\"Predicted values are:\\n\\n\", y_pred_BF[:10,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Restoring the results on real values:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Rescale\ny_scaler_config = scaler_config['output']\nmin_max_y = MinMaxScaler(feature_range=y_scaler_config['feature_range'])\nmin_max_y.fit(y_scaler_config['fit'])\n\ny_pred_BF_realValues = min_max_y.inverse_transform(y_pred_BF)\n#print(\"\\nFirst 6 real predicted values are:\\n\", y_pred_BF_realValues[:6,:])\n\n#y_pred_BF_realValues = mms_y.inverse_transform(y_pred_BF)\n#print(\"\\nFirst 6 real predicted values are:\\n\", y_pred_BF_realValues[:6,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Calculating the error:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t1=np.abs(y_pred_BF_realValues - y_test)\nt2=np.square(t1)\n\nt21=t2[:,0:1]\nt22=t2[:,1:2]\nt23=t2[:,2:3]\n\nt31=t21.sum()\nt32=t22.sum()\nt33=t23.sum()\n\nt41=t31/y_test.shape[0]\nt42=t32/y_test.shape[0]\nt43=t33/y_test.shape[0]\n\nRmse1_BF = np.sqrt(t41)\nRmse2_BF = np.sqrt(t42)\nRmse3_BF = np.sqrt(t43)\n\nt_max1 = np.max(y_test[:,0:1])\nt_min1 = np.min(y_test[:,0:1])\nt_max2 = np.max(y_test[:,1:2])\nt_min2 = np.min(y_test[:,1:2])\nt_max3 = np.max(y_test[:,2:3])\nt_min3 = np.min(y_test[:,2:3])\n\nPrmse1_BF = 100 * (Rmse1_BF / (t_max1 - t_min1))\nPrmse2_BF = 100 * (Rmse2_BF / (t_max2 - t_min2))\nPrmse3_BF = 100 * (Rmse3_BF / (t_max3 - t_min3))\n\nminutes3, seconds3= divmod(time3, 60)\nhours3, minutes3= divmod(minutes3, 60)\nprint(\"\\nTime for finding the best ANN by Black Fox service is \", time3,\"seconds(\",hours3,\"hours,\",minutes3,\"minutes and \",seconds3,\"seconds).\")\n\nprint(\"\\nRoot mean square error (WBE) = \", Rmse1_BF)\nprint(\"Root mean square error (WBCW) = \", Rmse2_BF)\nprint(\"Root mean square error (WBHW) = \", Rmse3_BF)\nprint(\"\\nPercentage root mean square error (WBE) = \", Prmse1_BF)\nprint(\"Percentage root mean square error (WBCW) = \", Prmse2_BF)\nprint(\"Percentage root mean square error (WBHW) = \", Prmse3_BF)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# RESULTS AND DISCUSSION"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\nTime to manually train one network is \", time1,\"seconds(\",hours1,\"hours,\",minutes1,\"minutes and \",seconds1,\"seconds ).\")\nprint(\"Time needed for tuning is \", time2,\"seconds(\",hours2,\"hours,\",minutes2,\"minutes and \",seconds2,\"seconds).\")\nprint(\"Time for finding the best ANN by Black Fox service is \", time3,\"seconds(\",hours3,\"hours,\",minutes3,\"minutes and \",seconds3,\"seconds).\")\nprint(\"\\nLet's visualize the results:\\n\")\n\nobjects = ('TrainingANN', 'TuningANN', 'BFservice')\ny_pos = np.arange(len(objects))\nperformance = [time1,time2,time3]\n \nplt.bar(y_pos, performance, align='center', alpha=1, color=('blue','red','green'))\nplt.xticks(y_pos, objects)\nplt.ylabel('Time (seconds)')\nplt.title('Time spent on making ANN')\n \nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### If we want to compare the results by making ANN manually and making it with Black Fox service, we would need to add the time spent in field \"TrainingANN\" and \"TuningANN\" in plot above, and that added time would be comparatible with time Black Fox service spent, which are so different, time needed for manually hard work is much larger then time Black Fox spent to make better results, that are given in the plot below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\nRoot mean square errors:\\n\")\nprint(\"Test set RMSE (WBE) on manually train one network is \", Rmse1_trained)\nprint(\"Test set RMSE (WBE) on tuning network is  \", Rmse1_tuning)\nprint(\"Test set RMSE (WBE) on Black Fox service's optimized network is \", Rmse1_BF)\nprint(\"\\nTest set RMSE (WBCW) on manually train one network is\", Rmse2_trained)\nprint(\"Test set RMSE (WBCW) on tuning network is  \", Rmse2_tuning)\nprint(\"Test set RMSE (WBCW) on Black Fox service's optimized network is \", Rmse2_BF)\nprint(\"\\nTest set RMSE (WBHW) on manually train one network is\", Rmse3_trained)\nprint(\"Test set RMSE (WBHW) on tuning network is  \", Rmse3_tuning)\nprint(\"Test set RMSE (WBHW) on Black Fox service's optimized network is \", Rmse3_BF)\n\nn_groups = 3\ngroup_1 = (Rmse1_trained, Rmse1_tuning, Rmse1_BF)\ngroup_2 = (Rmse2_trained, Rmse2_tuning, Rmse2_BF)\ngroup_3 = (Rmse3_trained, Rmse3_tuning, Rmse3_BF)\n \n# create plot\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nprint(index)\nbar_width = 0.25\nopacity = 0.8\n \nrects1 = plt.bar(index, group_1, bar_width,\nalpha=opacity,\ncolor='b',\nlabel='WBE')\n \nrects2 = plt.bar(index + bar_width, group_2, bar_width,\nalpha=opacity,\ncolor='g',\nlabel='WBCW')\n\nrects3 = plt.bar(index + bar_width + bar_width, group_3, bar_width,\nalpha=opacity,\ncolor='r',\nlabel='WBHW')\n \n#plt.xlabel('Person')\nplt.ylabel('Error')\n\nplt.title('Root mean square errors')\nplt.xticks(index + bar_width, ('TrainingANN', 'TuningANN', 'BFservice'))\nplt.legend()\n \nplt.tight_layout()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\Percentage root mean square errors:\\n\")\nprint(\"Test set PRMSE (WBE) on manually train one network is \", Prmse1_trained)\nprint(\"Test set PRMSE (WBE) on tuning network is  \", Prmse1_tuning)\nprint(\"Test set PRMSE (WBE) on Black Fox service's optimized network is \", Prmse1_BF)\nprint(\"\\nTest set PRMSE (WBCW) on manually train one network is\", Prmse2_trained)\nprint(\"Test set PRMSE (WBCW) on tuning network is  \", Prmse2_tuning)\nprint(\"Test set PRMSE (WBCW) on Black Fox service's optimized network is \", Prmse2_BF)\nprint(\"\\nTest set PRMSE (WBHW) on manually train one network is\", Prmse3_trained)\nprint(\"Test set PRMSE (WBHW) on tuning network is  \", Prmse3_tuning)\nprint(\"Test set PRMSE (WBHW) on Black Fox service's optimized network is \", Prmse3_BF)\n\nn_groups = 3\ngroup_1 = (Prmse1_trained, Prmse1_tuning, Prmse1_BF)\ngroup_2 = (Prmse2_trained, Prmse2_tuning, Prmse2_BF)\ngroup_3 = (Prmse3_trained, Prmse3_tuning, Prmse3_BF)\n \n# create plot\nfig, ax = plt.subplots()\nindex = np.arange(n_groups)\nbar_width = 0.25\nopacity = 0.8\n \nrects1 = plt.bar(index, group_1, bar_width,\nalpha=opacity,\ncolor='b',\nlabel='WBE')\n \nrects2 = plt.bar(index + bar_width, group_2, bar_width,\nalpha=opacity,\ncolor='g',\nlabel='WBCW')\n\nrects3 = plt.bar(index + bar_width + bar_width, group_3, bar_width,\nalpha=opacity,\ncolor='r',\nlabel='WBHW')\n \n#plt.xlabel('Person')\nplt.ylabel('Error ( % )')\n\nplt.title('Percentage root mean square errors')\nplt.xticks(index + bar_width, ('TrainingANN', 'TuningANN', 'BFservice'))\nplt.legend()\n \nplt.tight_layout()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Although we measured this three options, actually they are not so comparable, because in Python we had a man sitting in office and programming those neural networks(option 1 and 2) while in Black Fox service (option 3), he imported the same data set and the service did the rest, while he went to rest or dring coffe, for example, so actually, in Black Fox service he wrote few lines of code and thats all of hard work. Results in the given plots above speak for themself. As you can see, Black Fox service gave better results in less time and effort to create approximate results in Python as Black Fox did is immeasurably large."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}