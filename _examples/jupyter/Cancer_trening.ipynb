{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Cancer\n  \n### Problem explanation:\n\nLike other cancers, breast cancer is an uncontrolled growth of breast cells. Breast cancer occurs as a result of abnormal changes or mutation in the genes responsible for regulating the healthy growth of breast. The genes are in each cell’s nucleus, which acts as the “controller” of concern cell.\n\nThis abnormal tumour-like growth can be benign (not cancerous) or malignant (cancerous property). Benign tumours are close to normal in appearance, they grow comparatively slowly, and they do not invade or spread to nearby tissue and other parts of the body. As malignant cells have the potential to grow as cancer If they are left unchecked or untreated, they eventually can spread to nearby tissue and beyond an original tumour to other parts of the body.\n We need to classify a tumor as either benign or malignant based on cell descriptions gathered by microscopic examination. \nThe data was originally obtained from the University of Wisconsin Hospitals, Madison, from Dr. William H. Wolberg. Data set has 699 observations, all inputs are continuous, 65.5% of the examples are benign. The dataset itself is located here, in the field cancer.\n\nThis is classification problem and the results are two outputs, benign or malign. Model inputs are:\n \n* Clump thickness,\n* Uniformity of cell size,\n* Uniformiti of cell shape,\n* Marginal adhesion,\n* Single epithelial cell size,\n* Bare nuclei,\n* Bland chromatin,\n* Normal nucleoli,\n* Mitoses.\n\n### Problem solution:\nData set contains only 699 observations, so it is relatively small data set. We have divided the data set in two sets, training set, which contains 599 observations and test set, which contains 100 observations. We solved problem in two ways, with Python and Black Fox. We measured the model performance with K-cross validation (K=5) and for feature scaling we used min-max scaler. To stop training at the right time we used Early Stopping.\n "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Update Keras to latest version:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install keras==2.2.4",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# Data preprocessing\n#### Importing dataset:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n# Importing the date as data frame wich we will import with pandas using the read_csv function.\ndataframe = pd.read_csv('CancerData.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Dataset info:"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "dataframe.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Dataset description:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dataframe.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Dataset histogram :"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dataframe.hist(figsize=(10,10));",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Corelation heatmap:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.heatmap(dataframe.corr(), vmin=0, vmax=1);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "####  We will separate data frame into matrix X of features and dependent variable which is matrix y.  "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X = dataframe.iloc[:, 0:9].values\ny = dataframe.iloc[:, 9:11].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### We dont need to scale our data because they are already scaled, so we can split the dataset into the training set and test set."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Option 1 - manually finding best ANN:\n#### After many times of guessing the parameters for model this are the best one that we have found (you dont see our such enormous effort and huge time to find this parameters)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.callbacks import Callback, TensorBoard, ModelCheckpoint\nfrom keras.callbacks import EarlyStopping\n\nimport time\nstart1 = time.time()\n\nclassifier = Sequential()\nclassifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = 9))\nclassifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'sigmoid'))\nclassifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'sigmoid'))\nclassifier.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'sigmoid'))\nes = EarlyStopping(monitor = 'val_loss',\n                   mode = 'auto',\n                   #min_delta = 1e-2,\n                   patience = 150,\n                   verbose = 1,\n                   #baseline=0.4,\n                   restore_best_weights = True\n                  )\nclassifier.compile(optimizer = 'rmsprop', loss = 'mean_absolute_error', metrics = ['accuracy'])\nclassifier.fit(x = X_train, y = y_train, validation_split = 0.3, batch_size = 32, epochs = 3000, callbacks = [es], verbose=1)\n\nend1 = time.time()\n\ntime1 = int(end1-start1)\nminutes1, seconds1= divmod(time1, 60)\nhours1, minutes1= divmod(minutes1, 60)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### We just trained our artificial neural network on the training set and now it's time to make the prediction on the test set."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_pred_trained = classifier.predict(X_test)\n#print(\"Predicted values are:\\n\\n\", y_pred_trained[:10,:])\n\ny_winner = (y_pred_trained[:,0] > y_pred_trained[:,1])\ny_winner = np.where(y_winner == True, 1, 0)\ny_winner_test = (y_test[:,0] > y_test[:,1])\ny_winner_test = np.where(y_winner_test == True, 1, 0)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_winner, y_winner_test)\n\nerrorOnTestSetTrained = 100*(cm[0,1]+cm[1,0])/y_test.shape[0]\n\nprint(\"\\nTime to manually train one network is \", time1,\"seconds(\",hours1,\"hours,\",minutes1,\"minutes and \",seconds1,\"seconds ).\")\nprint(\"\\nWe got confusion matrix:\\n\",cm)\nprint(\"\\nTest set error on manually train one network, which we can read in confusion matrix is\",errorOnTestSetTrained,\"%.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Option 2 - Parameter tuning\n#### We have two type of parameters,  the parameters that are leaned from the model during the training and these are the weights, and we have some other parameters that stay fixed, and this parameters are called the hyperparameters. So for example this hyperparameters are the number of epoch, the bach size, the optimizer or the number of neurons in the layers. When we trained our ANN, we trained it with some fixed values of this hyperparameters, but meybe that by taking some other values we would get to better accuracy over all with K cross validation, and so that's what parameter tuning is all about, it consists of finding the best values of this hyperparameters and we are gonna do this with the technique called grid search that will test several combinations of this values and it will return the best choise that leads to the best accuracy with K cross validation."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nimport time\nstart2 = time.time()\n\ndef build_classifier(optimizer):\n    classifier = Sequential()\n    classifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'sigmoid', input_dim = 9))\n    classifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = optimizer, loss = 'mean_absolute_error', metrics = ['accuracy'])\n    return classifier\n\nTuning_classifier = KerasClassifier(build_fn = build_classifier)\nparameters = {'batch_size' : [10, 25, 32],\n              'epochs' : [100, 500, 3000],\n              'optimizer' : ['adam','rmsprop']}\n\ngrid_search = GridSearchCV(estimator=Tuning_classifier,\n                           param_grid=parameters,\n                           #scoring='accurasy',\n                           cv=10\n                          )\n\ngrid_search = grid_search.fit(X_train, y_train)\n\nbest_parameters = grid_search.best_params_\nbest_accuracy = grid_search.best_score_\n\nprint(\"Best parameters are :\\n\", best_parameters)\nprint(\"\\nBest accuracy is :\\n\", best_accuracy)\n\n\nend2 = time.time()\n\ntime2 = int(end2-start2)\nminutes2, seconds2= divmod(time2, 60)\nhours2, minutes2= divmod(minutes2, 60)\n\nprint(\"\\nTime training one network is \", time2,\"seconds(\",hours2,\"hours,\",minutes2,\"minutes and \",seconds2,\"seconds).\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### We got our artificial neural network which is in model named \"grid_search\". Now it's time to make the prediction on the test set."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_pred_tuning = grid_search.predict_proba(X_test)\n#print(\"Predicted values are:\\n\\n\", y_pred_tuning[:10,:])\n\ny_pred_rounded_tuning = (y_pred_tuning[:,0] > y_pred_tuning[:,1])\ny_pred_rounded_tuning = np.where(y_pred_rounded_tuning == True, 1, 0)\ny_winner_test_tuning = (y_test[:,0] > y_test[:,1])\ny_winner_test_tuning = np.where(y_winner_test_tuning == True, 1, 0)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_winner_test_tuning, y_pred_rounded_tuning)\n\nerrorOnTestSetTuning = 100*(cm[0,1]+cm[1,0])/y_test.shape[0]\n\nprint(\"\\nTime needed for tuning is \", time2,\"seconds(\",hours2,\"hours,\",minutes2,\"minutes and \",seconds2,\"seconds).\")\nprint(\"\\nWe got confusion matrix:\\n\",cm)\nprint(\"\\nTest set error with tuning, which we can read in confusion matrix is\",errorOnTestSetTuning,\"%.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Option 3 - Black fox service finding best ANN:"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Install Black fox service:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install blackfox-1.0.0.tar.gz",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Let's run Black Fox service to find best ANN:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Importing the BF service libraries\nfrom blackfox import BlackFox\nfrom blackfox import KerasOptimizationConfig\nfrom blackfox import OptimizationEngineConfig\nimport h5py\n#from keras.models import load_model\n#import numpy as np\n#import pandas as pd\n\nblackfox_url = 'http://147.91.204.14:32701'\nbf = BlackFox(blackfox_url)\n\nec = OptimizationEngineConfig(proc_timeout_miliseconds=2000000, population_size=50, max_num_of_generations=10)\nc = KerasOptimizationConfig(engine_config=ec, max_epoch = 3000, validation_split=0.1)\n\nimport time\nstart3 = time.time()\n\n# Use CTRL + C to stop optimization\n(ann_io, ann_info, ann_metadata) = bf.optimize_keras_sync(\n    input_set = X_train,\n    output_set = y_train,\n    config = c,\n    integrate_scaler=False,\n    network_path='OptimizedANNCancer_final.h5'\n)\n\nend3 = time.time()\ntime3 = int(end3-start3)\n\nprint('\\nann info:')\nprint(ann_info)\n\nprint('\\nann metadata:')\nprint(ann_metadata)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Data that we transfer to Black Fox service are not scaled, the service will scale the date by its own and when he finish his job he won't change the data, but service ofers us command to scale our data for prediction as he did and we will ofcourse use that."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Get metadata\nmeta = bf.get_metadata('OptimizedANNCancer_final.h5')\nscaler_config = meta['scaler_config']\n\n# Scale\nx_scaler_config = scaler_config['input']\nfrom sklearn.preprocessing import MinMaxScaler \nmin_max_x = MinMaxScaler(feature_range=x_scaler_config['feature_range'])\nmin_max_x.fit(x_scaler_config['fit'])\n\nX_test_minMaxScaled_withBF = min_max_x.transform(X_test)\n#print(X_test_minMaxScaled_withBF[:10,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Prediction:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Importing ANN model\nfrom keras.models import load_model\nmodel = load_model('OptimizedANNCancer_final.h5')\n\ny_pred_BF=model.predict(X_test_minMaxScaled_withBF)\n#print(\"Predicted values are:\\n\\n\", y_pred_BF[:10,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Restoring the results on real values:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Rescale\ny_scaler_config = scaler_config['output']\nmin_max_y = MinMaxScaler(feature_range=y_scaler_config['feature_range'])\nmin_max_y.fit(y_scaler_config['fit'])\n\ny_pred_BF_realValues = min_max_y.inverse_transform(y_pred_BF)\n#print(\"\\nFirst 6 real predicted values are:\\n\", y_pred_BF_realValues[:6,:])\n\n#y_pred_BF_realValues = mms_y.inverse_transform(y_pred_BF)\n#print(\"\\nFirst 6 real predicted values are:\\n\", y_pred_BF_realValues[:6,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Calculating the error:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_winner_BF = (y_pred_BF_realValues[:,0]>y_pred_BF[:,1])\ny_winner_BF = np.where(y_winner_BF == True, 1, 0)\ny_winner_test = (y_test[:,0]>y_test[:,1])\ny_winner_test = np.where(y_winner_test == True, 1, 0)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_winner_BF, y_winner_test)\n\nerrorOnTestSetBF = 100*(cm[0,1]+cm[1,0])/y_test.shape[0]\n\nminutes3, seconds3= divmod(time3, 60)\nhours3, minutes3= divmod(minutes3, 60)\n\nprint(\"\\nTime for finding the best ANN by Black Fox service is \", time3,\"seconds(\",hours3,\"hours,\",minutes3,\"minutes and \",seconds3,\"seconds).\")\nprint(\"\\nWe got confusion matrix:\\n\",cm)\nprint(\"\\nTest set error for finding the best ANN by Black Fox service, which we can read in confusion matrix is\",errorOnTestSetBF,\"%.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# RESULTS AND DISCUSSION"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\nTime to manually train one network is \", time1,\"seconds(\",hours1,\"hours,\",minutes1,\"minutes and \",seconds1,\"seconds ).\")\nprint(\"Time needed for tuning is \", time2,\"seconds(\",hours2,\"hours,\",minutes2,\"minutes and \",seconds2,\"seconds).\")\nprint(\"Time for finding the best ANN by Black Fox service is \", time3,\"seconds(\",hours3,\"hours,\",minutes3,\"minutes and \",seconds3,\"seconds).\")\nprint(\"\\nLet's visualize the results:\\n\")\n\nobjects = ('TrainingANN', 'TuningANN', 'BFservice')\ny_pos = np.arange(len(objects))\nperformance = [time1,time2,time3]\n \nplt.bar(y_pos, performance, align='center', alpha=1, color=('blue','red','green'))\nplt.xticks(y_pos, objects)\nplt.ylabel('Time (seconds)')\nplt.title('Time spent on making ANN')\n \nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### If we want to compare the results by making ANN manually and making it with Black Fox service, we would need to add the time spent in field \"TrainingANN\" and \"TuningANN\" in plot above, and that added time would be comparatible with time Black Fox service spent, which are so different, time needed for manually hard work is much larger then time Black Fox spent to make better results, that are given in the plot below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"\\nTest set error on manually train one network, which we can read in confusion matrix is\",errorOnTestSetTrained,\"%.\")\nprint(\"Test set error with tuning, which we can read in confusion matrix is\",errorOnTestSetTuning,\"%.\")\nprint(\"Test set error for finding the best ANN by Black Fox service, which we can read in confusion matrix is\",errorOnTestSetBF,\"%.\")\nprint(\"\\nLet's visualize the results:\\n\")\n\nobjects = ('TrainingANN', 'TuningANN', 'BFservice')\ny_pos = np.arange(len(objects))\nperformance = [errorOnTestSetTrained,errorOnTestSetTuning,errorOnTestSetBF]\n \nplt.bar(y_pos, performance, align='center', alpha=1, color=('blue','red','green'))\nplt.xticks(y_pos, objects)\nplt.ylabel('Error (%)')\nplt.title('Test set error')\n \nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Although we measured this three options, actually they are not so comparable, because in Python we had a man sitting in office and programming those neural networks(option 1 and 2) while in Black Fox service (option 3), he imported the same data set and the service did the rest, while he went to rest or dring coffe, for example, so actually, in Black Fox service he wrote few lines of code and thats all of hard work. Results in the given plots above speak for themself. As you can see, Black Fox service gave better results in less time and effort to create approximate results in Python as Black Fox did is immeasurably large."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}